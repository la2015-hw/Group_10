{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/la2015-hw/Group_10/blob/main/extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Please Read Before Running following Code Cells**\n",
        "\n",
        "\n",
        "Get Kaggle API key\n",
        "1. Navigate to Kaggle\n",
        "2. Naviagte to the Settings Page (Ensure you have a Kaggle account)\n",
        "3. Scroll to API and click \"Create New Token\"\n",
        "4. A JSON file downloads on you local machine\n",
        "\n",
        "Set Up Kaggle API\n",
        "1. Navigate to Google colab\n",
        "2. Click on files and click upload to session storage\n",
        "3. Once uploaded run the following commands in terminal\n",
        "\n",
        "```\n",
        "mkdir -p ~/.kaggle\n",
        "cp -f /content/kaggle.json ~/.kaggle/kaggle.json\n",
        "chmod 600 ~/.kaggle/kaggle.json\n",
        "```\n",
        "\n",
        "**If that does not work try this**\n",
        "\n",
        "```\n",
        "mkdir -p ~/.kaggle\n",
        "cp -f kaggle.json ~/.kaggle/kaggle.json\n",
        "chmod 600 ~/.kaggle/kaggle.json\n",
        "```\n",
        "4. API key has been set up and now you can read and write.\n",
        "\n",
        "**Reminder - Setup is necessary after each Session**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "A40B4-sFryui"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wggR1uw4c7S3"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"mustansireranpurwala/sdss-image-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "-TNC7ctG_PRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Image data Manipulation**"
      ],
      "metadata": {
        "id": "fa1SvgHQjgsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "file_path = '/home/mte/sdss_w_specz_train.h5'\n",
        "chunk_size = 10000\n",
        "output_csv = 'sdss_galaxies_with_colors.csv'\n",
        "\n",
        "def flux_to_magnitude(flux, zero_point=22.5):\n",
        "    flux = np.maximum(flux, 1e-10)\n",
        "    return -2.5 * np.log10(flux) + zero_point\n",
        "\n",
        "def extract_magnitudes_from_image(image_5band):\n",
        "    magnitudes = []\n",
        "    for band_idx in range(5):  # u, g, r, i, z\n",
        "        band_image = image_5band[:, :, band_idx]\n",
        "        total_flux = np.sum(band_image)\n",
        "        mag = flux_to_magnitude(total_flux)\n",
        "        magnitudes.append(mag)\n",
        "    return magnitudes\n",
        "\n",
        "def calculate_colors(u, g, r, i, z, e_bv):\n",
        "    A_u = 5.155 * e_bv\n",
        "    A_g = 3.793 * e_bv\n",
        "    A_r = 2.751 * e_bv\n",
        "    A_i = 2.086 * e_bv\n",
        "    A_z = 1.479 * e_bv\n",
        "\n",
        "    u_corr = u - A_u\n",
        "    g_corr = g - A_g\n",
        "    r_corr = r - A_r\n",
        "    i_corr = i - A_i\n",
        "    z_corr = z - A_z\n",
        "\n",
        "    return {\n",
        "        'u_mag': u_corr,\n",
        "        'g_mag': g_corr,\n",
        "        'r_mag': r_corr,\n",
        "        'i_mag': i_corr,\n",
        "        'z_mag': z_corr,\n",
        "        'u_minus_g': u_corr - g_corr,\n",
        "        'g_minus_r': g_corr - r_corr,\n",
        "        'r_minus_i': r_corr - i_corr,\n",
        "        'i_minus_z': i_corr - z_corr\n",
        "    }\n",
        "\n",
        "def classify_galaxy_death(u_minus_g, g_minus_r):\n",
        "    labels = []\n",
        "    for ug, gr in zip(u_minus_g, g_minus_r):\n",
        "        if ug > 1.5 and gr > 0.8:\n",
        "            labels.append('DEAD')\n",
        "        elif ug < 1.0 and gr < 0.6:\n",
        "            labels.append('ALIVE')\n",
        "        else:\n",
        "            labels.append('TRANSITIONAL')\n",
        "    return np.array(labels)\n",
        "\n",
        "\n",
        "with h5py.File(file_path, 'r') as f:\n",
        "    total_rows = f['ObjID'].shape[0]\n",
        "    print(f\"Total rows: {total_rows}\")\n",
        "\n",
        "    first_chunk = True\n",
        "    for start in range(0, total_rows, chunk_size):\n",
        "        end = min(start + chunk_size, total_rows)\n",
        "        print(f\"Processing rows {start} to {end}\")\n",
        "\n",
        "        objid = f['ObjID'][start:end]\n",
        "        ra = f['ra'][start:end]\n",
        "        dec = f['dec'][start:end]\n",
        "        e_bv = f['e_bv'][start:end]\n",
        "        spec_objid = f['specObjID'][start:end]\n",
        "        redshift = f['specz_redshift'][start:end]\n",
        "        redshift_err = f['specz_redshift_err'][start:end]\n",
        "        images = f['images'][start:end]\n",
        "\n",
        "        if images.shape[1] == 5 and images.shape[2] == 107:\n",
        "            images = np.transpose(images, (0, 2, 3, 1))\n",
        "\n",
        "        all_magnitudes = np.array([extract_magnitudes_from_image(img) for img in images])\n",
        "        u_mag, g_mag, r_mag, i_mag, z_mag = all_magnitudes.T\n",
        "\n",
        "        colors_dict = calculate_colors(u_mag, g_mag, r_mag, i_mag, z_mag, e_bv)\n",
        "\n",
        "        death_labels = classify_galaxy_death(colors_dict['u_minus_g'], colors_dict['g_minus_r'])\n",
        "\n",
        "\n",
        "        df = pd.DataFrame({\n",
        "            'ObjID': [x.decode('utf-8') for x in objid],\n",
        "            'ra': [float(x.decode('utf-8')) for x in ra],\n",
        "            'dec': [float(x.decode('utf-8')) for x in dec],\n",
        "            'e_bv': e_bv,\n",
        "            'specObjID': [int(x.decode('utf-8')) for x in spec_objid],\n",
        "            'specz_redshift': redshift,\n",
        "            'specz_redshift_err': redshift_err,\n",
        "            'u_mag': colors_dict['u_mag'],\n",
        "            'g_mag': colors_dict['g_mag'],\n",
        "            'r_mag': colors_dict['r_mag'],\n",
        "            'i_mag': colors_dict['i_mag'],\n",
        "            'z_mag': colors_dict['z_mag'],\n",
        "            'u_minus_g': colors_dict['u_minus_g'],\n",
        "            'g_minus_r': colors_dict['g_minus_r'],\n",
        "            'r_minus_i': colors_dict['r_minus_i'],\n",
        "            'i_minus_z': colors_dict['i_minus_z'],\n",
        "            'death_status': death_labels\n",
        "        })\n",
        "\n",
        "        df.to_csv(output_csv, mode='a', index=False, header=first_chunk)\n",
        "        first_chunk = False\n",
        "\n",
        "print(\"Finished processing SDSS file. Data saved to CSV.\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"Loading Galaxy Zoo 2 data...\")\n",
        "gz2 = pd.read_csv('zoo2MainSpecz.csv')\n",
        "\n",
        "gz2 = gz2[pd.to_numeric(gz2['specobjid'], errors='coerce').notna()]\n",
        "gz2['specobjid'] = gz2['specobjid'].astype(np.int64)\n",
        "\n",
        "df = pd.read_csv(output_csv)\n",
        "df['specObjID'] = df['specObjID'].astype(np.int64)\n",
        "\n",
        "\n",
        "df_matched = df.merge(gz2, left_on='specObjID', right_on='specobjid', how='inner')\n",
        "print(f\"Successfully matched {len(df_matched)} galaxies with Galaxy Zoo 2\")\n",
        "\n",
        "\n",
        "df_matched.to_csv('sdss_gz2_matched.csv', index=False)\n",
        "\n",
        "print(\"All processed data saved!\")"
      ],
      "metadata": {
        "id": "FdjWPCoHjaMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**To push data back to kaggle**\n",
        "\n",
        "1. Run the following code to create a folder to be pushed back which contains a metadata file"
      ],
      "metadata": {
        "id": "tyTnQ75xHcIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "dataset_folder = \"/content/processed_dataset\"\n",
        "\n",
        "os.makedirs(dataset_folder, exist_ok=True)\n",
        "\n",
        "metadata = {\n",
        "    \"title\": \"SDSS Image Dataset - Processed\",\n",
        "    \"id\": \"mustansireranpurwala/sdss-image-dataset\",\n",
        "    \"licenses\": [\n",
        "        {\"name\": \"CC0-1.0\"}\n",
        "    ]\n",
        "}\n",
        "\n",
        "with open(f\"{dataset_folder}/dataset-metadata.json\", \"w\") as f:\n",
        "    json.dump(metadata, f, indent=4)\n",
        "\n",
        "print(\"dataset-metadata.json created in\", dataset_folder)"
      ],
      "metadata": {
        "id": "7C0RlMV0H5yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Open Terminal and run the following commands\n",
        "\n",
        "```\n",
        "cp -r /root/.cache/kagglehub/datasets/mustansireranpurwala/sdss-image-dataset/versions/1/sdss_w_specz_valid.h5 /content/processed_dataset/\n",
        "```\n",
        "This command moves the dataset from the root to the processed_data folder\n",
        "```\n",
        "kaggle datasets version -p /content/my_dataset_to_push -m \"Test push from Colab\"\n",
        "```\n",
        "This command initiates the push to kaggle\n",
        "\n",
        "3. The processed dataset has sucessfully been pushed"
      ],
      "metadata": {
        "id": "CsETUay6IFJk"
      }
    }
  ]
}